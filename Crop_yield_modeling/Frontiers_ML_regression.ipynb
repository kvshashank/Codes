{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15+"
    },
    "colab": {
      "name": "Frontiers_ML_regression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwxQNuGuYD7s"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAShEKDzYD7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "d8150d2e-0cc9-4fba-880a-208f0ea250c1"
      },
      "source": [
        "##### Find optimal number of principal components #####\n",
        "\n",
        "res = pd.read_csv(\"yields.csv\")\n",
        "res = res[\"Yield\"]\n",
        "\n",
        "pred = pd.read_csv(\"combined_indices.csv\")\n",
        "pred = pred.iloc[:,1:]\n",
        "components = list(range(1,13))\n",
        "pca_all = PCA(n_components=0.999)\n",
        "pca_all.fit(pred)\n",
        "explained_variance = np.cumsum(pca_all.explained_variance_ratio_)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "plt.plot(components, explained_variance, '-bo')\n",
        "plt.xlabel('No. of Principal Components', fontsize=15, labelpad=15)\n",
        "plt.ylabel('Cumulative Variance', fontsize=15, labelpad=15)\n",
        "plt.title('Explained Variance Ratio', fontsize=15, pad=15)\n",
        "ax.xaxis.set_tick_params(labelsize=15)\n",
        "ax.yaxis.set_tick_params(labelsize=15)\n",
        "plt.subplots_adjust(left=0.2, bottom=0.2)\n",
        "plt.show()\n",
        "#plt.savefig(\"explained_variance.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-227eefd85dfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplained_variance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-bo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No. of Principal Components'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cumulative Variance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3362\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1526\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 242\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (12,) and (11,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYRWnHknYD73"
      },
      "source": [
        "def prepare_data():\n",
        "   # Import response variable\n",
        "   res = pd.read_csv(\"yield.csv\")\n",
        "   res = res[\"Yield\"]\n",
        "\n",
        "   # Import predictors\n",
        "   pred = pd.read_csv(\"combined_indices.csv\")\n",
        "   pred = pred.iloc[:,1:]\n",
        "\n",
        "   # Concatenate response and predictor dataframes\n",
        "   data = pd.concat([pred,res], axis=1)\n",
        "\n",
        "   # Separate predictors and response again\n",
        "   X = data.iloc[:,:-1]\n",
        "   Y = data.iloc[:,-1]\n",
        "\n",
        "   # Choose 80% of data randomly for training and rest for testing\n",
        "   X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=41)\n",
        "\n",
        "   return(X_train, X_test, Y_train, Y_test)\n",
        "\n",
        "def metrics(y_pred, y_test):\n",
        "    r2 = r2_score(y_pred, y_test.to_list())\n",
        "    rmse = sqrt(mean_squared_error(y_pred, y_test.to_list()))\n",
        "    return r2, rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLdoqST3YD78"
      },
      "source": [
        "##### Linear Methods ######"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2kG9DL-YD8A",
        "outputId": "d2681ff7-0ace-49b7-bc7b-dd02d2462ebe"
      },
      "source": [
        "#### Principal Component Regression #####\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = prepare_data()\n",
        "pca = PCA(n_components=0.95)\n",
        "pca_train = pd.DataFrame(pca.fit_transform(X_train))\n",
        "pca_test = pd.DataFrame(pca.transform(X_test))\n",
        "\n",
        "linear = LinearRegression(fit_intercept=True, normalize=False, copy_X=True)\n",
        "linear.fit(pca_train, Y_train)\n",
        "y_pred = linear.predict(pca_test)\n",
        "\n",
        "r2, rmse = metrics(y_pred, Y_test)\n",
        "print r2, rmse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.899920257713598 0.327769140332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAos0vbQYD8F",
        "outputId": "672728a7-bd47-4244-8155-6a7cb57bbdbc"
      },
      "source": [
        "#### Ridge Regression ####\n",
        "alpha_arr = np.arange(0.1,10,0.5)\n",
        "\n",
        "def ridge(alpha, x_train, y_train, x_test):\n",
        "    model = Ridge(alpha = alpha)\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "    return y_pred\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = prepare_data()\n",
        "\n",
        "#### Perform k-fold CV. kf_split only produces indices of rows #####\n",
        "kf = KFold(n_splits=5)\n",
        "r2_arr = []\n",
        "rmse_arr = []\n",
        "results = pd.DataFrame([],columns=[\"Alpha\",\"R^2\",\"RMSE\"],index=np.arange(0, len(alpha_arr)))\n",
        "\n",
        "for i in range(0,len(alpha_arr)): \n",
        " for train_indices, test_indices in kf.split(X_train):\n",
        "    x_train = X_train.iloc[train_indices,:].reset_index(drop=True)\n",
        "    y_train = Y_train.iloc[train_indices].reset_index(drop=True)\n",
        "    x_test = X_train.iloc[test_indices,:].reset_index(drop=True)\n",
        "    y_test = Y_train.iloc[test_indices].reset_index(drop=True)\n",
        "    \n",
        "    # Ridge\n",
        "    alpha = alpha_arr[i] \n",
        "    y_pred = ridge(alpha, x_train, y_train, x_test)\n",
        " \n",
        "    # Calculate R^2 and rmse\n",
        "    r2, rmse = metrics(y_pred, y_test)\n",
        "    r2_arr.append(r2)\n",
        "    rmse_arr.append(rmse)\n",
        "    \n",
        " results[\"Alpha\"][i] = alpha\n",
        " results[\"R^2\"][i] = np.mean(r2_arr)\n",
        " results[\"RMSE\"][i] = np.mean(rmse_arr)\n",
        "\n",
        "#### Based on the results, choose alpha = 5\n",
        "#### Get final results\n",
        "alpha=5\n",
        "y_pred = ridge(alpha, X_train, Y_train, X_test)\n",
        "r2, rmse = metrics(y_pred, Y_test)\n",
        "print r2, rmse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.882382861849851 0.331021067958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf4mpEq5YD8K"
      },
      "source": [
        "##### Non Linear Methods #####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY-ORzbMYD8O",
        "outputId": "e3b0226a-53e3-48ee-b97b-d8be42d3b7c5"
      },
      "source": [
        "##### Support Vector Regression #####\n",
        "X_train, X_test, Y_train, Y_test = prepare_data()\n",
        "tuned_parameters = [{'kernel':['linear','rbf'], 'C':[0.1, 0.2, 0.3, 0.5, 1, 2, 5, 10], \n",
        "                     'epsilon':[0.01, 0.05, 0.1, 0.2, 0.5]}]\n",
        "grid = GridSearchCV(SVR(), tuned_parameters, cv=5)\n",
        "grid.fit(X_train, Y_train.values.ravel())\n",
        "best_params = grid.best_params_\n",
        "\n",
        "## Get final results\n",
        "model = SVR(kernel=best_params[\"kernel\"], C=best_params[\"C\"], epsilon=best_params[\"epsilon\"])\n",
        "model.fit(X_train, Y_train)\n",
        "Y_pred = model.predict(X_test)\n",
        "r2, rmse = metrics(Y_pred, Y_test)\n",
        "print best_params\n",
        "print r2, rmse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'epsilon': 0.2, 'C': 0.1, 'kernel': 'linear'}\n",
            "0.8891888035312312 0.330659177012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjTFldsGYD8T",
        "outputId": "0cf315c9-ca58-42d7-9c00-c8d39cdd6d9e"
      },
      "source": [
        "##### Random Forest Regression #####\n",
        "X_train, X_test, Y_train, Y_test = prepare_data()\n",
        "tuned_parameters = [{'n_estimators':[10,20,50,100,250,500], 'max_features':[\"auto\",\"sqrt\",\"log2\"], \n",
        "                    'min_samples_split':[2,4,6], 'random_state':[100]}]\n",
        "grid = GridSearchCV(RandomForestRegressor(), tuned_parameters, cv=5)\n",
        "grid.fit(X_train, Y_train.values.ravel())\n",
        "best_params = grid.best_params_\n",
        "print best_params\n",
        "model = RandomForestRegressor(n_estimators=best_params[\"n_estimators\"], max_features=best_params[\"max_features\"],\n",
        "                             min_samples_split=best_params[\"min_samples_split\"], random_state=5)\n",
        "model.fit(X_train, Y_train.values.ravel())\n",
        "y_pred = model.predict(X_test)\n",
        "r2, rmse = metrics(y_pred, Y_test)\n",
        "print r2, rmse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_features': 'auto', 'min_samples_split': 2, 'random_state': 100, 'n_estimators': 20}\n",
            "0.9303951830599273 0.257441691032\n",
            "[0.92878654 0.00942086 0.0084738  0.00354312 0.00418719 0.00602454\n",
            " 0.00607116 0.01286564 0.00171019 0.01031302 0.00416758 0.00443638]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jawl6q_9YD8Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}